---
title: 'Homework 4'
author: 'Daria Dubovskaia'
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
# chunks
knitr::opts_chunk$set(eval=TRUE, message=FALSE, warning=FALSE, fig.height=5, fig.align='center')

# libraries
library(partykit)
library(kableExtra)
library(ranger)
library(viridis)
library(tidyverse)
library(caTools)
library(reshape)
library(summarytools)
library(gridExtra)
library(MASS) 
library(lubridate)
library(skimr)
library(yardstick)
library(randomForest)
library(corrplot)
library(Hmisc)
library(jtools)
library(glmnet)
library(caret)
library(smotefamily)
library(recipes)
library(ggplot2)
library(fastDummies)
library(janitor)
library(forecast)
library(MASS)
library(performance)
library(car)
library(vip)



# random seed
set.seed(42)
```

```{r common functions}
#' nice_table
#' 
#' @param df
#' @param fw
nice_table <- function(df, cap=NULL, cols=NULL, dig=3, fw=F){
  if (is.null(cols)) {c <- colnames(df)} else {c <- cols}
  table <- df %>% 
    kable(caption=cap, col.names=c, digits=dig) %>% 
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      html_font = 'monospace',
      full_width = fw)
  return(table)
}

#' glmnet_cv_aicc
#'
#' @param fit
#' @param lambda
#'
#' @return
#' @export
#'
#' @examples
glmnet_cv_aicc <- function(fit, lambda = 'lambda.min'){
  whlm <- which(fit$lambda == fit[[lambda]])
  with(fit$glmnet.fit,
       {
         tLL <- nulldev - nulldev * (1 - dev.ratio)[whlm]
         k <- df[whlm]
         n <- nobs
         return(list('AICc' = - tLL + 2 * k + 2 * k * (k + 1) / (n - k - 1),
                     'BIC' = log(n) * k - tLL))
       })
}

#' coeff2dt
#'
#' @param fitobject 
#' @param s 
#'
#' @return
#' @export
#'
#' @examples
coeff2dt <- function(fitobject, s) {
  coeffs <- coef(fitobject, s) 
  coeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) 

  # reorder the variables in term of coefficients
  return(coeffs.dt[order(coeffs.dt$coefficient, decreasing = T),])
}
```

## Overview

The real estate market is a dynamic and intricate setting where a variety of factors affect the price of real estate. Listings on Airbnb, a big part of this market, are not an exception. Numerous factors, such as location, amenities, and local demand, influence these prices. Comprehending and forecasting the cost of Airbnb listings is essential for both hosts looking to establish competitive rates and visitors looking for good value. The conventional hotel sector has also been impacted by Airbnb's growth, drawing attention from economists and market analysts. The goal in this project was to forecast Airbnb listings' price. Our objective was to gain insights into key factors that impact Airbnb listing prices in New York City by developing predictive models to estimate Airbnb listing prices based on relevant factors and evaluating the performance of the predictive models and identify opportunities for improvement.

We started by carefully reviewing the dataset to find problems like outliers, missing values, and possible predictor multicollinearity. This procedure, which was essential for guaranteeing the accuracy of our analysis, resulted in preprocessing and data cleaning, where we took care of these problems. We used Lasso Regression and Linear Regression models for our analysis after the data were prepared. These models were selected because they are well-suited to comprehending how different features affect the dependent variable, which in this case is the cost of Airbnb listings. Given its popularity for being easily understood and straightforward, Linear Regression gave us a starting point model. However, by penalizing less significant features, Lasso Regression's feature selection capability allowed us to better understand the most significant predictors.


------------------------------------------------------------------------

## 1. Data Preparation

```{r data_load}
# Load data from Github
data <- read.csv("https://raw.githubusercontent.com/ex-pr/DATA_622/main/HW%204/nyc_listings_2023.csv")
```

### 1.1 Summary Statistics

The dataset contained **38,792** observations of 18 variables.

The information was listings for New York City from October, 2023, and each record includes information about a single rental property, such as its type, location, cost, and review-related details.
The `price` was the target, it specified the price of a Airbnb listing per night.
Specifically:

-   `id`:  Unique identifier for the listing.
-   `name`: The listing's name or description.
-   `host_id`: Unique identifier for the host.
-   `host_name`: The host's name.
-   `neighbourhood_group`: The borough in which the listing was situated.
-   `neighbourhood`: The specific neighbourhood in which the listing was situated.
-   `latitude`, `longitude`: Location coordinates for the listing.
-   `room_type`: The kind of room being provided (private room, entire apartment, shared room or hotel room).
-   `price`: Cost per night for the listed property.
-   `minimum_nights`: A minimum number of nights needed to make a reservation.
-   `number_of_reviews`: Total reviews that this listing had gotten.
-   `last_review`: Date of the last review.
-   `reviews_per_month`: The average monthly number of reviews.
-   `calculated_host_listings_count`: Total number of listings that the host had.
-   `availability_365`: The number of days a year that the listing is bookable.
-   `number_of_reviews_ltm`: Number of Reviews  for the last twelve months.
-   `license`: Details about the listing's license.

Regression techniques were the focus of the algorithm selection process because the price variable in our dataset was continuous.
The data preparation steps had been tailored to suit these algorithms, with an emphasis on managing missing values, scaling and normalizing the features, and potentially encoding categorical variables when necessary.

**Linear Regression**: This algorithm was a useful place to start.
The relationship between the independent variables and the target variable was assumed to be linear.
It was an excellent baseline model because it was straightforward, comprehensible, and didn't require complicated parameter tuning.

**Lasso Regression**: A kind of linear regression with a penalty term (Least Absolute Shrinkage and Selection Operator).
The magnitude of the coefficients' absolute value was equivalent to the penalty that was applied.
Because this kind of regression performed feature selection by shrinking less significant feature coefficients to zero, it was helpful when we had a large number of features.

**K-Fold Cross Validation**: We applied it to evaluate our models' performance.
Using this method, the dataset was divided into k subsets, of which one was used as the test set and the others as the training set.
Every subset served as the test set once during the k repetitions of this process.
In order to prevent overfitting and underfitting, it made sure that each observation from the original dataset had an equal chance of showing up in the training and test sets.

The target variable's nature as a quantitative measure, price, influenced the choice of these algorithms.
For modeling the relationship between the predictors and a continuous outcome, linear and lasso regression were preferred due to their simplicity and effectiveness.
However, multicollinearity and irrelevant features could affect the performance of lasso and linear regression; this was where feature selection and regularization techniques came into play.
Reliability in validating model performance across dataset subsets had be aided by k-fold cross validation.

The data source: <http://insideairbnb.com/get-the-data>

```{r head_data}
# Check first rows of data
DT::datatable(
      data[1:25,],
      extensions = c('Scroller'),
      options = list(scrollY = 350,
                     scrollX = 500,
                     deferRender = TRUE,
                     scroller = TRUE,
                     dom = 'lBfrtip',
                     fixedColumns = TRUE, 
                     searching = FALSE), 
      rownames = FALSE) 
```

The table below provided a a summary statistics of the New York City listings market for 2023, highlighting variations in listing prices, booking requirements, and guest interaction.

The were a small number of missing values (0.01%) in the `host_name` and `name` columns, a sizable amount (26.7%) in the `last_review` and `reviews_per_month` columns, and a very high percentage (92.42%) of missing values in the `license` column.
Prior to doing additional analysis, these missing values had to be addressed.

Average price, minimum night requirement, distribution of room types, and average availability is given in this summary.
The prices of the listings varied from 0 to 30,000 dollars, with an average of 215.95 dollars.
There was a minimum of 1 to 1250 nights required, with an average of 30.64 nights.The dataset included the following room types: hotel room, shared room, private room, and entire home/apt.
Of the room types, entire home/apt accounted for 54.96% of listings.
Listings were available for 148.75 days a year on average, but this could range from no availability to being available all year round.
There were anywhere from none to many reviews for each listing, which suggested different levels of interaction or length of time listed on the platform.
The average number of reviews per month was 1.08, although this varies substantially between listings.

```{r summ}
# Check summary statistics of the data
print(dfSummary(data, text.graph.col = FALSE, graph.col = FALSE, style = "grid", valid.col = FALSE), headings = FALSE, max.tbl.height = 400, footnote = NA, col.width=5, method="render")
```

### 1.2 Column change

Columns `neighbourhood_group, neighbourhood, room_type` were transformed to categorical variables. This change was performed to better depict the variables' inherent categorical character. The column `last_review` was transformed to date format as it contained a date of the last review.

```{r to_factor}
# Copy original data
imputed_df <- data

# Transform binary variables to factors
cols <- c("neighbourhood_group", "neighbourhood", "room_type")
imputed_df[cols] <- lapply(imputed_df[cols], factor) 

# Convert 'last_review' to datetime objects
imputed_df$last_review <- as.Date(imputed_df$last_review)
```

### 1.3 Missing values, drop columns

Managing missing values was one of the critical problems to fix before building the models.

The missing values for continuous variable `reviews_per_month` (10,352 rows) were imputed with 0 as it corresponded with 0 `number_of_reviews` (10,352 rows with 0 number of reviews). The missing values for date column `last review` were imputed with the minimum date from the column. Instead of the date format, we counted the amount of days since the earliest review. The NaN values in the `last_review and reviews_per_month` columns all occured for examples where no reviews were given in the first place.

The rest of the columns with missing values were not useful for the analysis and predictions: `host_name` and `name` columns contained name of the host and listing, column `last_review` contained information about the date of the last review. 
The column `license` showed if a listing had license (according to the law, specific short-term rentals require a license), this column had more than 90% of the missing data and was dropped from the data.
Columns `id, host_id` were dropped as well.
Although, they didn't have any missing values, they contained unique identification numbers for each listing and host which were not useful for the further analysis.

```{r check_na}
# check NAs in number_of_reviews and last_review
dim(imputed_df[imputed_df$number_of_reviews == 0,])
sum(is.na(imputed_df$last_review))
```

```{r na_impute}
# Set seed for constant results
set.seed(42)

# Impute NAs for 'reviews_per_month' with their 0
imputed_df <- imputed_df %>% 
              mutate(across(c('reviews_per_month'), ~replace_na(., 0)))

# remove columns id, host_id, host_name, name, license
imputed_df <- imputed_df %>% 
              dplyr::select(-c(id, host_id, host_name, name, license)) 

```

```{r}
# Find the earliest date
earliest <- min(imputed_df$last_review, na.rm = TRUE)

# Replace NA values with the earliest date
imputed_df$last_review <- replace_na(imputed_df$last_review, earliest)

# Convert dates to ordinal and subtract the ordinal value of the earliest date
imputed_df$last_review <- as.integer(as.Date(imputed_df$last_review) - as.Date(earliest))

# Remove last_review column
imputed_df <- imputed_df %>% 
              dplyr::select(-c(last_review)) 
```

### 1.3 Encoding, rename colums

We assured that our dataset was appropriate for a broader range of algorithms that require numerical input by using one-hot encoding, boosting the potential accuracy and effectiveness of our later analysis.

`neighbourhood_group and room_type` were recognized as categorical columns that would benefit from one-hot encoding.

Three new columns were created for `room_type`: `Entire home/apt, Hotel room, and Private room`.
Each of these columns accepted a binary value, indicating whether the corresponding room type was present (1) or absent (0).

Three new columns were created for `neighbourhood_group`: `neighbourhood_group_Bronx, neighbourhood_group_Brooklyn, neighbourhood_group_Manhattan, neighbourhood_group_Queens`.
Each of these columns accepted a binary value, indicating whether the corresponding neighbourhood group was present (1) or absent (0).

The last category of each original categorical variable was eliminated throughout the encoding procedure to avoid multicollinearity and reduce redundancy (`neighbourhood_group_Staten Island, room_type_Shared room`).
The original columns were dropped after explanatory analysis.

The column names were fixed to remove space and transform all letters to lowercase using clean_names() function from janitor library.

Column `neighbourhood` wasn't encoded or used in the models as it was highly granular, with numerous distinct categories, and one-hot encoding could result in a dataset that was extremely high dimensional. We assumed it was not crucial for the prediction, given that we already had geographical coordinates and neighbourhood_group included.

```{r encode_binary}
# Copy data without NAs
encoded_df <- imputed_df

# One hot encoding for 'neighbourhood_group' and 'room_type'
encoded_df <- dummy_cols(encoded_df, select_columns = c('neighbourhood_group', 'room_type')) 



encoded_df <- encoded_df %>%
           dplyr::select(-c('neighbourhood_group_Staten Island', 'room_type_Shared room')) %>% 
           clean_names()

#encoded_df <- dummy_cols(encoded_df, select_columns = c('neighbourhood'))

#encoded_df <- encoded_df %>%
           #dplyr::select(-c('neighbourhood_Fort Wadsworth')) %>% 
          # clean_names()
```

New feature `availability_ratio` was created to facilitate interpretation, it offered a percentage or portion of the year that the listing was accessible.

```{r new_col}
# create feature availability_ratio
encoded_df$availability_ratio <- encoded_df$availability_365 / 365
```


### 1.4 Outliers

We used boxplots to detect outliers.

-   There were notable anomalies for the `price`, with certain listings charging astronomically high costs in contrast to the majority. The outleirs were removed in the log transformed column.

-   `minimum_nights` column also displayed anomalies, with certain listings having extraordinarily high minimum nights requirements. As we saw per graph, there were just 6 listings out of 38,792 with minimum number of nights greater than 500. Hosts could set up these high numbers of minimum nights when they didn't want to accept new guests. As a results, these number for minimum nights were not real. We removed them as these wrong numbers could skew the results. 

-   `number_of_reviews`, `reviews_per_month`. A small percentage of listings had an unusually high amount of total reviews. Some listings were more popular than others because they received a lot of reviews each month. For example, these listings could represent a hotel, each hotel could have a lot of rooms in one listing for rent. As a result, one listing received a lot of reviews for many rooms inside it. But the number of listings with reviews greater than 700 was just 9 and the number of reviews per month greater than 40 was 3, they were not representative of the typical listings, they were likely to skew your predictive modeling results. This is a common approach when the outliers constitute a very small percentage of the data and are not central to the analysis. Because the linear regression and Lasso regression models are sensitive to the size and distribution of the input features, outliers can significantly affect the performance of these models.

-   `calculated_host_listings_count`. Compared to the average host, some hosts had a lot more listings than others. Which could also happen in case some hosts owned multiple property.

-   `availability_ratio`. Listings with extremely high availability all year round could be properties that were specifically intended for rental use.

-   `number_of_reviews_ltm`: Some listings had received a significant amount of reviews in just the past year, comparable to the overall number of reviews. As it was mentioned above, it could be some hotels. The listings with number of reviews for the last 12 months greater than 200 were removed.

If these outliers were not properly addressed, they may represent special cases or mistakes in data entry, which could skew the analysis.

```{r outliers}
# Numeric columns to check for outliers
continuous_vars <- c("price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "availability_ratio")

# List to store plots
plots <- list()

# Generate boxplots for each variable
for(i in 1:length(continuous_vars)) {
  p <- ggplot(encoded_df, aes_string(y = continuous_vars[i])) + 
    geom_boxplot() +
    theme_minimal()
  plots[[i]] <- p
}

# Arrange the plots in a grid
grid.arrange(grobs = plots, ncol = 3)
```

```{r}
dim(encoded_df[encoded_df$minimum_nights  > 500,])
dim(encoded_df[encoded_df$number_of_reviews  > 700,])
dim(encoded_df[encoded_df$reviews_per_month  > 40,])
dim(encoded_df[encoded_df$number_of_reviews_ltm  > 200,])

encoded_df <- encoded_df %>%
         filter(minimum_nights <= 500 & number_of_reviews  <= 700 & reviews_per_month  <= 40 & number_of_reviews_ltm  <= 200)
```


The `price` column had a small number of extremely high values. This skewness was normalized with the aid of a log transformation, which improved the symmetry of the data and made it more suitable for linear models. The outliers were removed to exclude extreme values in the price data.

```{r}
# log+1 price to fix the skeweness
encoded_df$log_price <- log1p(encoded_df$price)
# Filter the data frame where log(1 + price) is less than 8
encoded_df <- encoded_df[encoded_df$log_price < 8, ]

# Further filter the data frame where log(1 + price) is greater than 3
encoded_df <- encoded_df[encoded_df$log_price > 3, ]

```



### 1.6 Summary Statistics for transformed data

After the data transformation, no missing values detected.

New columns were added (`neighbourhood_group_bronx, neighbourhood_group_brooklyn,  neighbourhood_group_manhattan, neighbourhood_group_queens, room_type_entire_home_apt,    room_type_hotel_room, room_type_private_room, availability_ratio`) while other were removed (`id, name, host_id, host_name, last_review, license, log_price`).

Overall, where the outliers had been eliminated, the main changes brought about by filtering were seen in the maximum values of `minimum_nights, number_of_reviews, reviews_per_month, number_of_reviews_ltm, log_price`. Because of this, the means and standard deviations of these variables had somewhat decreased, which had made the data more condensed and probably more appropriate for linear and Lasso regression analysis.

```{r head_data_new}
DT::datatable(
      encoded_df[1:25,],
      extensions = c('Scroller'),
      options = list(scrollY = 350,
                     scrollX = 500,
                     deferRender = TRUE,
                     scroller = TRUE,
                     dom = 'lBfrtip',
                     fixedColumns = TRUE, 
                     searching = FALSE), 
      rownames = FALSE) 
```

```{r summ_new}
print(dfSummary(encoded_df, text.graph.col = FALSE, graph.col = FALSE, style = "grid", valid.col = FALSE), headings = FALSE, max.tbl.height = 500, footnote = NA, col.width=50, method="render")
```



## 2. Data Exploration

### 2.1 Continuous Variables

`availability_ratio` displayed a distribution that was more variable. While some postings were available all year long, the most of the hosts were not available all the year. Latitude, longitude had a normal distribution, most of the hosts were concetrated in a specific area. Also, log_price had normal distribution after transformation. All other distributions were right-skewed. Severe skewness in predictors or the target variable could be problematic in regression analysis because it could go against the normalcy assumption, particularly in linear regression models. In addition to causing non-linearity and heteroscedasticity (non-constant variance), skewed distributions can also make the model more susceptible to outliers. It was addressed after splitting the data for training and testing.

```{r cont_plot}
# Choose numeric variables
numeric_vars <-c("log_price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "availability_ratio", "number_of_reviews_ltm", "latitude", "longitude")

# List to store plots
plots <- list()

# Generate histograms for each variable
for (i in 1:length(numeric_vars)) {
  p <- ggplot(encoded_df, aes_string(x = numeric_vars[i])) + 
    geom_histogram(aes(y=..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    ggtitle(paste0('Distribution of ', numeric_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots,  ncol = 2)
```


### 2.2 Categorical Variables

The distribution of Airbnb listings among New York City's boroughs showed noticeably more listings in some boroughs than in others, which could indicate that there was more demand or a larger selection of lodging in those areas. The most properties were found in `Manhattan` followed by `Brooklyn` which was probably because it had been a popular destination for both leisure and business travelers.

The various kinds of rooms that were available in Airbnb listings showed that some room types were more common than others, which could be a reflection of the hosts' preferences or trends in visitor demand. `Entire home/apt` followed by `Private room` were the most common room type among all neighborhood groups, indicating that hosts in NYC were more likely to provide entire apartments as opposed to shared spaces.

It was crucial to comprehend these distributions in order to comprehend the dynamics of New York City's Airbnb listings. For instance, a borough with a lot of listings might be a commercial center or a well-liked vacation spot. In a similar vein, the popularity of a specific room type can reveal the kind of lodging that visitors to NYC usually look for.


```{r factor_plot}
# Choose factor variables
factor_vars <- c("neighbourhood_group", "room_type")

# List to store plots
plots <- list()

# Generate barplots for each variable
for (i in 1:length(factor_vars)) {
  p <- ggplot(encoded_df, aes_string(x = factor_vars[i])) + 
    geom_bar(fill = "lightgreen", color = "black", alpha = 0.7) +
    ggtitle(paste0('Distribution of ', factor_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots, ncol = 1)
```


Plotting the distribution of Airbnb properties by type of room across several neighborhood groups in New York City, the data was displayed as a grouped bar chart below. 

Manhattan was followed by Brooklyn in terms of the quantity of Airbnb listings. Entire home/apt was the most popular listing, followed by Private room. This suggests that Airbnb stays were also common in Brooklyn.

Compared to Manhattan and Brooklyn, there were noticeably fewer listings in Queens, the Bronx, and Staten Island. Of these, Queens had a higher number of listings than Staten Island and the Bronx.

In all boroughs, private room listings were the second most prevalent, with a notable concentration in Brooklyn and Manhattan.

There weren't many listings for shared rooms, which could be because hosts prefer not to provide shared spaces or because there weren't as much demand for this kind of lodging.

There were variations in the distribution of room types among the boroughs, which could be due to factors such as the local housing market, zoning laws, or the travel and demographic patterns of each community.



```{r borough_room}
# Group by borough, count room type in each borough
group_room <- encoded_df %>%
  group_by(neighbourhood_group) %>%
  count(room_type)

# Bar plot borough vs number of listings by room type
ggplot(group_room, aes(x = neighbourhood_group, y = n, fill = room_type)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme_minimal() +
  labs(title = "Borough vs Properties, NYC", x = "Borough", y = "Number of Properties") +
  scale_fill_discrete(name = "Room Type") 

```


The mix of neighborhoods in the top 10 reflected the diverse appeal of New York City's numerous neighborhoods by showcasing a range of areas dispersed across different parts of the city.

The neighborhood's strong representation of Williamsburg and Bedford-Stuyvesant underscored Brooklyn's growing appeal as a destination for travelers to New York City.

The list included Manhattan neighborhoods like Harlem, Hell's Kitchen, Upper West Side, and Upper East Side, highlighting the city's ongoing appeal because of its convenient location and wealth of attractions.

Popular neighborhoods that draw a varied range of visitors included those with cultural, historical, or entertainment significance, such as Hell's Kitchen and Harlem, which are well-known for their restaurants and close proximity to Broadway.


```{r neigh_count}
group_neigh <- encoded_df %>% 
  group_by(neighbourhood) %>% 
  count() %>% 
  arrange(desc(n))

ggplot(group_neigh[1:10,], aes(x = reorder(neighbourhood, -n), y = n, fill = neighbourhood)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme_minimal() +
  labs(title = "Neighbourhood vs Properties, NYC", x = "Neighbourhood", y = "Number of Properties") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")
```


### 2.3 Target variable

**Log Price vs Numerical Variables**: Price didn't seem to be strongly correlated with either latitude or longitude. Nonetheless, there were pockets of higher pricing in specific locations, most likely associated with upscale or more well-known neighborhoods. Few listings had a very high minimum night requirement, while the majority of listings had fewer minimum nights. The quantity of required minimum nights and the cost did not exhibit a definite linear relationship. The majority of expensive listings did not require a minimum of one night.

In general, listings with a large number of reviews were less expensive. This could suggest that listings at lower prices were being booked and reviewed more frequently. The prices of the listings with fewer reviews varied greatly. Listings with more reviews per month typically had lower prices, much like the number of reviews does. Additionally, this plot implied that listings that were reviewed and probably booked more frequently were more reasonably priced.

The price and the quantity of listings a host had were not clearly correlated. Prices varied widely for hosts with few or many listings. The prices for the various yearly availability levels varied greatly.
The lack of a discernible pattern suggested that price couldn't be strongly correlated with availability. Similar to the total number of reviews, listings with a higher number of recent reviews typically had lower prices. The trend suggested that listings with lower prices could be booked and reviewed more frequently.

```{r numeric_price}
# Plot target vs numeric columns
for (i in numeric_vars) {
  p <- ggplot(encoded_df, aes_string(x = i, y = "log_price")) +
    geom_point() +
    theme_bw() +
    labs(title = paste('Price vs', i), x = i, y = 'Price')
  
  print(p)
}
```

The toriginal price column had a highly skewed distribution. This could cause problems for machine learning algorithms such as linear regression. A log transformation and removal of outliers made the distribution look much closer to normal.

```{r}
# Create the distribution plot for `price`
p1 <- ggplot(encoded_df, aes(x=price)) +
      geom_histogram(aes(y=..density..), binwidth=1, colour="black", fill="white") +
      geom_density(alpha=.2, fill="#FF6666") +
      ggtitle("Distribution of Price")

# Create the distribution plot for log(1 + `price`)
p2 <- ggplot(encoded_df, aes(x=log_price)) +
      geom_histogram(aes(y=..density..), binwidth=1, colour="black", fill="white") +
      geom_density(alpha=.2, fill="#FF6666") +
      ggtitle("Distribution of log(1 + Price)") +
      xlab("log(1 + price)")

# Create a Q-Q plot for log(1 + `price`)
p3 <- ggplot() +
      stat_qq(aes(sample = log_price), data = encoded_df) +
      stat_qq_line(aes(sample = log_price), data = encoded_df) +
      ggtitle("Q-Q Plot of log(1 + Price)")

# Arrange the plots in a 1x3 grid
grid.arrange(p1, p2, p3, ncol = 3)

```


**Price vs Categorical Variables**: 

The median prices of various neighborhood groups differed noticeably from one another. The common belief that Manhattan was a more expensive area was supported by the fact that the borough's median prices tend to be higher than those of other Manhattan neighborhoods. Compared to individual rooms and hotel rooms, entire homes and apartments were typically more expensive. There was a significant variance in the kind and caliber of these listings, as seen by the larger price variance for complete houses or apartments.

```{r}
# Plot target vs categorical
for (i in factor_vars) {
  p <- ggplot(encoded_df, aes_string(x = i, y = "log_price")) +
    geom_boxplot() +
    theme_bw() +
    labs(title = paste('Price vs', i), x = i, y = 'Price')
  print(p)
}
```


It appeared that a listing's location (shown by latitude and longitude) affected its price, but not in a straightforward linear way. It was likely that neighborhood-specific factors were important. A few factors that clearly affected price were the type of room and the quantity of reviews. Listings with lower prices appeared to draw more reviews. A large number of the numerical variables didn't clearly demonstrate a linear relationship with price, suggesting that the intricacies of the data could be beyond the scope of a basic linear model.
Possibility of Non-linear and Interaction Effects: Non-linear modeling or the addition of interaction terms could be required to more accurately depict the relationship between these variables and the price, given the absence of obvious linear trends.

### 2.4 Correlation

There was a positive correlation between higher `prices` and listings in `Manhattan` (0.15). This implied that Manhattan real estate was more expensive to list, probably as a result of the borough's popularity and strategic location. In contrast, there was a negative correlation (-0.09 and -0.07, respectively) between the price of listings in Brooklyn and Queens, suggesting that these boroughs typically had lower prices than Manhattan. 

`Price` and `entire homes/apartments` had a positive correlation (0.10), indicating that the price of these listings was usually higher than that of shared accommodations. A negative correlation (-0.11) indicated that private rooms were typically less expensive than whole houses or apartments. 

Price and longitude had a negative correlation (-0.11), which could suggest that listings in Brooklyn and Queens, which are further east, were typically less expensive.
The positive correlation between latitude and price was less strong (0.03), indicating a potential trend toward slightly higher listing prices for listings further north.

The neighbourhood group encodings exhibited significant negative correlations with each other. For example, the correlation between neighbourhood group Manhattan and neighbourhood group Brooklyn was -0.56, and the correlation between neighbourhood group Manhattan and neighbourhood group Queens was -0.36. Given that these were mutually exclusive categories, this was expected.

Correlations between room type encodings and neighbourhood groups were also strongly negative. For example, there was a negative correlation (-0.81) between room_type_Private room and room_type_Entire home/apt. This suggested that these kinds of rooms belong to exclusive groups.

There was a significant inverse relationship between latitude and longitude (-0.48). This implied a geographical trend that was geographically accurate for New York City: moving west corresponds with moving north (higher latitude).

The relationship between availability_365 and calculated_host_listings_count was moderately positive (0.22). This could suggest that hosts who had a larger number of listings were typically more available all year long.

There existed a moderate negative correlation (-0.11) between number_of_reviews and calculated_host_listings_count. This could indicate that hosts with fewer properties tended to have listings that had received more reviews, either because they had been active on the platform longer or because they concentrated more on a single listing.


```{r corr}
# Check correlation
rcore <- rcorr(as.matrix(encoded_df %>% dplyr::select(where(is.numeric))))
# Take correlation coeff
coeff <- rcore$r
# Build corr plot
corrplot(coeff, tl.cex = 0.5, tl.col="black", method = 'color', addCoef.col = "black",
         type="upper", order="hclust", number.cex=0.5,
         diag=FALSE)
```

```{r corr_numbers}
tst <- encoded_df %>% dplyr::select(where(is.numeric))
tst <- tst[,-17]
kable(cor(drop_na(tst))[,17], "html", escape = F, col.names = c('Coefficient')) %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1, bold = T) 
```


## 3. Split data

Finally, we split our data into train (75%) and test (25%) datasets to evaluate model performance before we proceeded to prediction. The train data contained 29089 records, test data 9545.

```{r split}
# random seed
set.seed(42)

# 80/20 split of the data set
sample <- sample.split(encoded_df$price, SplitRatio = 0.75)
train_data  <- subset(encoded_df, sample == TRUE)
test_data   <- subset(encoded_df, sample == FALSE)

# Check dimensions of train and test data
dim(train_data)
dim(test_data)
```

As outliers showed, the were extremely high prices per night (`$30,000`) in contrast to the mean (`$216`). As a result, the price distribution was right-skewed. This indicated that the skewness was positive. To lessen the skewness, log transformation was used after splitting the data for training and testing to avoid data leakage. Transformation by log+1 was preferable because division by zero was problematic. The same transformation was appled to `minimum_nights`. We also applied the Box-Cox Transformation to `number_of_reviews, reviews_per_month, calculated_host_listings_count, number_of_reviews_ltm` due to their right-skeweness to stabilize variance and improve its normalcy. We added 1 in boxCox() to ensure all values were positive, which is necessary for the Box-Cox transformation

```{r transform, fig.keep="none"}
# Log transformation for target variable to remove skeweness
train_transformed <- train_data
test_transformed <- test_data

# Log transformation for "price","minimum_nights"
cols_transform <- c("price", "minimum_nights")

for (i in cols_transform) {
  train_transformed[[i]]<- log(train_transformed[[i]]+1)
  test_transformed[[i]]<- log(test_transformed[[i]]+1)
}

# Boxcox transformation for "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "availability_ratio"
b_boxcox <- boxcox(lm((train_transformed$number_of_reviews+1) ~ 1))
b_lambda <- b_boxcox$x[which.max(b_boxcox$y)]
b_trans <- BoxCox(train_transformed$number_of_reviews+1, b_lambda)
train_transformed$number_of_reviews <- b_trans 
b_trans <- BoxCox(test_transformed$number_of_reviews+1, b_lambda)
test_transformed$number_of_reviews <- b_trans 


c_boxcox <- boxcox(lm((train_transformed$reviews_per_month+1) ~ 1))
c_lambda <- c_boxcox$x[which.max(c_boxcox$y)]
c_trans <- BoxCox(train_transformed$reviews_per_month+1, c_lambda)
train_transformed$reviews_per_month <- c_trans 
c_trans <- BoxCox(test_transformed$reviews_per_month+1, c_lambda)
test_transformed$reviews_per_month <- c_trans 

d_boxcox <- boxcox(lm((train_transformed$calculated_host_listings_count) ~ 1))
d_lambda <- d_boxcox$x[which.max(d_boxcox$y)]
d_trans <- BoxCox(train_transformed$calculated_host_listings_count, d_lambda)
train_transformed$calculated_host_listings_count <- d_trans 
d_trans <- BoxCox(test_transformed$calculated_host_listings_count, d_lambda)
test_transformed$calculated_host_listings_count <- d_trans 

e_boxcox <- boxcox(lm((train_transformed$number_of_reviews_ltm+1) ~ 1))
e_lambda <- e_boxcox$x[which.max(e_boxcox$y)]
e_trans <- BoxCox(train_transformed$number_of_reviews_ltm+1, e_lambda)
train_transformed$number_of_reviews_ltm <- e_trans 
e_trans <- BoxCox(test_transformed$number_of_reviews_ltm+1, e_lambda)
test_transformed$number_of_reviews_ltm <- e_trans 
```

For linear regression models, these transformations aided in stabilizing the variance and improving the symmetry of the distributions. The data was better suited for predictive modeling after transformations.

```{r cont_plot}
# Choose numeric variables
numeric_vars <-c("price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm", "availability_ratio")

# List to store plots
plots <- list()

# Generate histograms for each variable
for (i in 1:length(numeric_vars)) {
  p <- ggplot(train_transformed, aes_string(x = numeric_vars[i])) + 
    geom_histogram(aes(y=..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    ggtitle(paste0('Distribution of ', numeric_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots, ncol = 2)
```



## 4. Models

### 4.1 Model 1 - Linear Regression

For the first model, Linear Regression, we dropped:
- `neighbourhood_group, room_type` features as we encoded them and used encoded columns instead of these originals. 

- `availability_365, log_price` as we created new feature availability ratio and transformed price with log after splitting data to train and test, so we didn't need the previous column log_price.

- `number_of_reviews, reviews_per_month` as they were highly correlated, we kept only number of reviews for the last 12 months.

- `neighbourhood` in order to avoid high dimensionality.

```{r}
# remove some features from the model
train_model_1 <- train_transformed %>% 
                dplyr::select(-c(neighbourhood, neighbourhood_group, room_type, availability_365, number_of_reviews, reviews_per_month, log_price)) 

test_model_1 <- test_transformed %>% 
                dplyr::select(-c(neighbourhood, neighbourhood_group, room_type, availability_365, number_of_reviews, reviews_per_month, log_price)) 
```

We first configured five-fold cross-validation. The training data was divided into five parts, and the model was trained and validated five times, using the remaining parts as the training set and a different part as the validation set each time. This made it easier to estimate the model's performance with greater accuracy. After, the Linear Regression model was trained.

```{r model_1}
set.seed(42)

# setup cross-validation
ctrl <- trainControl(method = "cv", number = 5)

# fit a regression model and use k-fold CV to evaluate performance
model_1 <- train(price ~ ., data = train_model_1, method = "lm", trControl = ctrl)
```


#### Model Performance

How well the model fit the data was shown in the summary of residuals. The residuals were between -1.9809 and 3.7455. A somewhat symmetric residual distribution around zero was suggested by a median near -0.0850, which is generally a positive indicator.

The F-statistic was `1,941`, the adjusted R-squared was `0.464`, and out of the 14 variables, all had statistically significant p-values. The model was statistically significant, as indicated by the F-statistic and p-value of less than 2.2e-16.The adjusted R2 indicated that only 46% of the variance in the response variable could be explained by the predictor variables. Even though the model explained a sizable percentage of the variance in log_price, a sizable portion remained unaccounted for by the model.

Residual standard error was `0.579`. It provided an estimate of the residuals' standard deviation and, consequently, the typical error in log_price prediction made by the model.

RMSE was `0.557`, showing how far predictions fell from measured true values using Euclidean distance.

A positive coefficient indicated that the predictor and the outcome variable were positively correlated.
For example, the room_type_entire_home_apt had a positive coefficient of about 0.815. This suggested that the log_price of Airbnb listings for complete homes or apartments was approximately 0.815 units higher than the log_price of listings for other types of listings (like shared rooms or hotel rooms), holding all other variables constant.
When a coefficient was positive, it indicated that the outcome variable rised along with the predictor.


A  negative relationship between the predictor and the outcome variable was indicated by a negative coefficient. For instance, latitude variable had a coefficient of roughly -1.136. This implied that, if all other variables stayed the same, the log_price of Airbnb listings decreased as latitude rised, which in the context of geographic coordinates usually meant moving northward.
A negative coefficient indicated a decrease in the outcome variable with an increase in the predictor.

```{r, fig.height=4}
print(model_1)
summary(model_1)

# validate and calculate RMSE
model_1.valid <- predict(model_1, newdata = test_model_1)
model_1.eval <- bind_cols(target = test_model_1$price, predicted=unname(model_1.valid))
model_1.rmse <- sqrt(mean((model_1.eval$target - model_1.eval$predicted)^2)) 

# plot targets vs predicted
model_1.eval %>%
  ggplot(aes(x = target, y = predicted)) +
  geom_point(alpha = .3) +
  geom_smooth(method="lm", color='grey', alpha=.3, se=FALSE) +
  labs(title=paste('RMSE:',round(model_1.rmse,1)))
```

```{r metrics_1}
multi_metric <- metric_set(mape, smape, mase, mpe, yardstick::rmse)
model1_df <- model_1.eval %>% multi_metric(truth=target, estimate=predicted)
b <- summary(model_1)
```


```{r res_table_1}
results_lm_tbl <- tibble(
                      Model = character(),
                      mape = numeric(), 
                      smape = numeric(), 
                      mase = numeric(), 
                      mpe = numeric(), 
                      "RMSE" = numeric(),
                      AIC = numeric(),
                      "Adjusted R2" = numeric()
                )

results_lm_tbl <- results_lm_tbl %>% add_row(tibble_row(
                      Model = "Model 1: Linear Regression, cv",
                      mape = model1_df[[1,3]],
                      smape = model1_df[[2,3]],
                      mase = model1_df[[3,3]],
                      mpe = model1_df[[4,3]],
                      "RMSE" = model1_df[[5,3]],
                      AIC = AIC(model_1$finalModel),
                      "Adjusted R2" = b$adj.r.squared
                     ))
```


#### Model Assumptions

Remaining versus Fitted tests for homoscedasticity and nonlinearity. To indicate homoscedasticity, the points should ideally be distributed randomly around the horizontal line. The residuals in the plot were almost distributed without any recognized pattern.

If the residuals are regularly distributed, it is verified by the Standard Q-Q plot. The dashed line indicates that the points are distributed normally. There was some variation at the tails of the plot, suggesting possible problems with normalcy.

Scale-Location plot had points to be dispersed equally throughout the fitted value range.
The plot indicated potential problems with equal variance, as the residuals' spread widened as fitted values increased.

Leverage versus Residuals made it easier to spot outliers that unreasonably affected the model. Influential points could be those that were prominently located above the dashed Cook's distance lines or far to the right of the plot. A few of the points had high leverage and/or high Cook's distance, which made them potentially significant.


The diagnostic plots implied that there could be some transgressions of the homoscedasticity and residual normality assumptions of linear regression. Taking into account variable transformations or using models more resilient to such problems may be beneficial. The Residuals vs. Leverage plot's indication of influential points may call for additional research. To determine whether these data points should be eliminated or whether there is a significant explanation for their status as outliers. 

```{r diag_plots_1}
model_1_final <- model_1$finalModel

par(mfrow = c(2, 2))
plot(lmModel)
```

The variance inflation factor (VIF) quantified the extent to which multicollinearity with other model predictors inflated the variance of a regression coefficient. As a general rule, high multicollinearity was indicated by a VIF greater than 5 or 10.

High VIF values indicated that variables such as availability_ratio, latitude, longitude, and neighbourhood_group_manhattan could be collinear with other variables in the model.
Because it could inflate the standard errors of the coefficients and reduce the reliability of the model estimates, this collinearity could be problematic.
The VIF only implied that a variable was not offering unique information when there were other variables present; it did not, however, implied that a variable was unimportant.

```{r vif_lm1, fig.height=4}
vif_values <- vif(model_1_final)
vif_values <- rownames_to_column(as.data.frame(vif_values), var = "var")

vif_values %>%
  ggplot(aes(y=vif_values, x=var)) +
  coord_flip() + 
  geom_hline(yintercept=5, linetype="dashed", color = "red") +
  geom_bar(stat = 'identity', width=0.3 ,position=position_dodge()) 
```


### 4.2 Model 2 - Lasso

To perform lasso regression, we used functions from the glmnet package. This package required the response variable to be a vector and the set of predictor variables to be of the class data.matrix. We used the transformed train and test data (with log and boxcox transformations) without choosing particular variables.

```{r}
# Transform to matrix
set.seed(42)
t0 <- train_transformed %>% dplyr::select(-c(log_price, availability_365))
X <- model.matrix(price ~ ., data=t0)[,-1]
Y <- t0$price
```

Next, we used the glmnet() function to fit the lasso regression model and specify alpha=1. To determine what value to use for lambda, we performed k-fold cross-validation and identify the lambda value that produced the lowest test mean squared error (MSE). 

The following attribute settings were selected for the model:

-   type.measure = "mse" - The type.measure is set to minimize the Mean Squared Error for the model.
-   nfold = 10 - Given the size of the dataset we defaulted to 10-fold cross-validation.
-   family = gaussian - For Linear Regression
-   alpha = 1 - The alpha value of 1 sets the variable shrinkage method to lasso.
-   standardize = TRUE - Finally, we explicitly set the standardization attribute to TRUE; this will normalize the prediction variables around a mean of zero and a standard deviation of one before modeling.

The coefficients extracted using lambda.min minimized the mean cross-validated error.

```{r}
# Fit lasso model
set.seed(42)
lasso_cv <- cv.glmnet(
  x=X,y=Y, # Y already logged in prep
  family = "gaussian",
  type.measure="mse",
  standardize = TRUE, # standardize
  nfold = 10,
  alpha=1) # alpha=1 is lasso

# Find optimal lambda value that minimizes test MSE
best_lambda <- lasso_cv$lambda.min
best_lambda


#produce plot of test MSE by lambda value
plot(lasso_cv) 
```

#### Model Performance

After, we analyzed the final model produced by the optimal lambda value.

```{r}
#find coefficients of best model
lasso_model <- glmnet(X, Y, alpha = 1, lambda = best_lambda)
#coef(lasso_model)

as.data.frame(as.matrix(coef(lasso_model, s = "lambda.min"))) %>%
  arrange(desc(s1)) %>%
  nice_table(cap='Model Coefficients', cols='Est')
```


```{r}
t1 <- test_transformed %>% dplyr::select(-c(log_price, availability_365))
X_test <- model.matrix(price ~ ., data=t1)[,-1]
y_test <- t1[,"price"] 
```

```{r}
y_pred <- predict(
  lasso_model, 
  newx = X_test,
  s = best_lambda)
```

```{r}
# validate and calculate RMSE
model_2.valid <- predict(model_1, newdata = test_model_1)
model_2.eval <- bind_cols(target = test_model_1$price, predicted=unname(model_1.valid))
model_2.rmse <- sqrt(mean((model_1.eval$target - model_1.eval$predicted)^2)) 

# plot targets vs predicted
model_1.eval %>%
  ggplot(aes(x = target, y = predicted)) +
  geom_point(alpha = .3) +
  geom_smooth(method="lm", color='grey', alpha=.3, se=FALSE) +
  labs(title=paste('RMSE:',round(model_1.rmse,1)))
```

```{r}
t2 <- t1
t2$price_pred <- y_pred[,1]

m_df <- t2 %>% multi_metric(truth=price, estimate=price_pred)
m_df
```

```{r res_table_2}
results_lm_tbl <- results_lm_tbl %>% add_row(tibble_row(
                      Model = "Model 2: Lasso",
                      mape = m_df[[1,3]],
                      smape = m_df[[2,3]],
                      mase = m_df[[3,3]],
                      mpe = m_df[[4,3]],
                      "RMSE" = m_df[[5,3]],
                      AIC = NA,
                      "Adjusted R2" = NA
                     ))
```


#### Model Assumptions

```{r diag_plots_2}
model_2_final <- model_2$finalModel

par(mfrow = c(2, 2))
plot(lmModel)
```

```{r vif_lm2, fig.height=4}
vif_values <- vif(model_1_final)
vif_values <- rownames_to_column(as.data.frame(vif_values), var = "var")

vif_values %>%
  ggplot(aes(y=vif_values, x=var)) +
  coord_flip() + 
  geom_hline(yintercept=5, linetype="dashed", color = "red") +
  geom_bar(stat = 'identity', width=0.3 ,position=position_dodge()) 
```

Descriptive Statistics Overview:
Latitude & Longitude: These are geographic coordinates, which might be useful to understand the spatial distribution of prices.
Price: There's a significant range in prices, with a maximum of $30,000, which seems quite high. The mean is $215.89, but the median is much lower at $135, indicating a right-skewed distribution.
Minimum Nights: Majority of listings require a 30-night stay, but some listings require up to 500 nights, which is quite high.
Number of Reviews: Varies widely, indicating different levels of popularity or longevity of listings.
Reviews per Month: Some listings have high activity, while others have none.
Calculated Host Listings Count: Indicates how many listings each host manages, ranging from 1 to 602.
Availability_365: Ranges from 0 to 365 days, indicating varying levels of availability throughout the year.
Number of Reviews LTM (Last Twelve Months): Provides recent activity level of the listing.
Encoded Neighbourhood Groups & Room Types: These are categorical variables encoded as binary, useful for regression analysis.
Next steps in the analysis process:

Feature Selection:
We need to determine which features are most relevant to predicting the price. The encoded neighborhood groups and room types are definitely important. Other factors like location (latitude and longitude), availability, and host listing count may also play a significant role.

------------------------------------------------------------------------

Methodologies:

Week 4: Classification: Naive Bayes

Employ Naive Bayes classification to predict Airbnb listing categories (entire apartment, private room, shared room) based on listing characteristics.

Week 12: Resampling and Model Selection

Utilize k-fold cross-validation and train-test split techniques to evaluate the performance of various regression models (linear regression, ridge regression, Lasso regression) in predicting Airbnb listing prices.
Analysis:

Exploratory Data Analysis: Visualize and summarize the data to understand the distribution of variables and identify potential relationships between them.

Feature Engineering: Create new features from existing data to capture additional information and improve the predictive power of the models.

Model Building: Train and evaluate various regression models using the prepared data and the selected methodologies.

Model Validation: Assess the performance of the final model using unseen data to validate its generalizability.

Conclusions:

Identify the most significant factors influencing Airbnb listing prices in New York City.
Develop a predictive model that accurately estimates Airbnb listing prices based on the identified factors.
Provide insights into pricing strategies and market trends for Airbnb hosts in New York City.
Business Impact:

Help Airbnb hosts optimize their listing prices to maximize revenue and occupancy rates.
Assist potential Airbnb guests in making informed decisions based on price and listing characteristics.
Provide valuable insights to policymakers and urban planners for understanding the dynamics of the short-term rental market in New York City.
