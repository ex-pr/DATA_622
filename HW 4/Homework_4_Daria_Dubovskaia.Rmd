---
title: 'Homework 4'
author: 'Daria Dubovskaia'
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: united
editor_options:
  chunk_output_type: console
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
# chunks
knitr::opts_chunk$set(eval=TRUE, message=FALSE, warning=FALSE, fig.height=5, fig.align='center')

# libraries
library(partykit)
library(kableExtra)
library(ranger)
library(viridis)
library(tidyverse)
library(caTools)
library(reshape)
library(summarytools)
library(gridExtra)
library(MASS) 
library(lubridate)
library(skimr)
library(yardstick)
library(randomForest)
library(corrplot)
library(Hmisc)
library(jtools)
library(glmnet)
library(caret)
library(smotefamily)
library(recipes)
library(ggplot2)
library(fastDummies)
library(janitor)
library(forecast)
library(MASS)
library(performance)
library(car)
library(vip)


# random seed
set.seed(42)
```

```{r common functions}
#' nice_table
#' 
#' @param df
#' @param fw
nice_table <- function(df, cap=NULL, cols=NULL, dig=3, fw=F){
  if (is.null(cols)) {c <- colnames(df)} else {c <- cols}
  table <- df %>% 
    kable(caption=cap, col.names=c, digits=dig) %>% 
    kable_styling(
      bootstrap_options = c("striped", "hover", "condensed"),
      html_font = 'monospace',
      full_width = fw)
  return(table)
}

#' glmnet_cv_aicc
#'
#' @param fit
#' @param lambda
#'
#' @return
#' @export
#'
#' @examples
glmnet_cv_aicc <- function(fit, lambda = 'lambda.min'){
  whlm <- which(fit$lambda == fit[[lambda]])
  with(fit$glmnet.fit,
       {
         tLL <- nulldev - nulldev * (1 - dev.ratio)[whlm]
         k <- df[whlm]
         n <- nobs
         return(list('AICc' = - tLL + 2 * k + 2 * k * (k + 1) / (n - k - 1),
                     'BIC' = log(n) * k - tLL))
       })
}

#' coeff2dt
#'
#' @param fitobject 
#' @param s 
#'
#' @return
#' @export
#'
#' @examples
coeff2dt <- function(fitobject, s) {
  coeffs <- coef(fitobject, s) 
  coeffs.dt <- data.frame(name = coeffs@Dimnames[[1]][coeffs@i + 1], coefficient = coeffs@x) 

  # reorder the variables in term of coefficients
  return(coeffs.dt[order(coeffs.dt$coefficient, decreasing = T),])
}
```

## Overview

**Predicting factors that influence Airbnb listing prices in New York City.**

Goal of the Research:

Gain insights into key factors that impact Airbnb listing prices in New York City.
Develop a predictive model to estimate Airbnb listing prices based on relevant factors.
Evaluate the performance of the predictive model and identify opportunities for improvement.

------------------------------------------------------------------------

## 1. Data Preparation

**Data Acquisition**: Collect Airbnb listing data from a reliable source, such as Inside Airbnb (insideairbnb.com).

```{r data_load}

# Load data from Github
data <- read.csv("https://raw.githubusercontent.com/ex-pr/DATA_622/main/HW%204/nyc_listings_2023.csv")
```

### 1.1 Summary Statistics

The dataset contained **38,792** observations of 18 variables.

The information was listings for New York City from October, 2023, and each record includes information about a single rental property, such as its type, location, cost, and review-related details.
The `price` was the target, it specified the price of a Airbnb listing per night.
Specifically:

-   `id`:  Unique identifier for the listing.
-   `name`: The listing's name or description.
-   `host_id`: Unique identifier for the host.
-   `host_name`: The host's name.
-   `neighbourhood_group`: The borough in which the listing was situated.
-   `neighbourhood`: The specific neighbourhood in which the listing was situated.
-   `latitude`, `longitude`: Location coordinates for the listing.
-   `room_type`: The kind of room being provided (private room, entire apartment, shared room or hotel room).
-   `price`: Cost per night for the listed property.
-   `minimum_nights`: A minimum number of nights needed to make a reservation.
-   `number_of_reviews`: Total reviews that this listing had gotten.
-   `last_review`: Date of the last review.
-   `reviews_per_month`: The average monthly number of reviews.
-   `calculated_host_listings_count`: Total number of listings that the host had.
-   `availability_365`: The number of days a year that the listing is bookable.
-   `number_of_reviews_ltm`: Number of Reviews  for the last twelve months.
-   `license`: Details about the listing's license.

Regression techniques were the focus of the algorithm selection process because the price variable in our dataset was continuous.
The data preparation steps had been tailored to suit these algorithms, with an emphasis on managing missing values, scaling and normalizing the features, and potentially encoding categorical variables when necessary.

**Linear Regression**: This algorithm was a useful place to start.
The relationship between the independent variables and the target variable was assumed to be linear.
It was an excellent baseline model because it was straightforward, comprehensible, and didn't require complicated parameter tuning.

**Lasso Regression**: A kind of linear regression with a penalty term (Least Absolute Shrinkage and Selection Operator).
The magnitude of the coefficients' absolute value was equivalent to the penalty that was applied.
Because this kind of regression performed feature selection by shrinking less significant feature coefficients to zero, it was helpful when we had a large number of features.

**K-Fold Cross Validation**: We applied it to evaluate our models' performance.
Using this method, the dataset was divided into k subsets, of which one was used as the test set and the others as the training set.
Every subset served as the test set once during the k repetitions of this process.
In order to prevent overfitting and underfitting, it made sure that each observation from the original dataset had an equal chance of showing up in the training and test sets.

The target variable's nature as a quantitative measure, price, influenced the choice of these algorithms.
For modeling the relationship between the predictors and a continuous outcome, linear and lasso regression were preferred due to their simplicity and effectiveness.
However, multicollinearity and irrelevant features could affect the performance of lasso and linear regression; this was where feature selection and regularization techniques came into play.
Reliability in validating model performance across dataset subsets had be aided by k-fold cross validation.

The data source: <http://insideairbnb.com/get-the-data>

```{r head_data}
# Check first rows of data
DT::datatable(
      data[1:25,],
      extensions = c('Scroller'),
      options = list(scrollY = 350,
                     scrollX = 500,
                     deferRender = TRUE,
                     scroller = TRUE,
                     dom = 'lBfrtip',
                     fixedColumns = TRUE, 
                     searching = FALSE), 
      rownames = FALSE) 
```

The table below provided a a summary statistics of the New York City listings market for 2023, highlighting variations in listing prices, booking requirements, and guest interaction.

The were a small number of missing values (0.01%) in the `host_name` and `name` columns, a sizable amount (26.7%) in the `last_review` and `reviews_per_month` columns, and a very high percentage (92.42%) of missing values in the `license` column.
Prior to doing additional analysis, these missing values had to be addressed.

Average price, minimum night requirement, distribution of room types, and average availability is given in this summary.
The prices of the listings varied from 0 to 30,000 dollars, with an average of 215.95 dollars.
There was a minimum of 1 to 1250 nights required, with an average of 30.64 nights.The dataset included the following room types: hotel room, shared room, private room, and entire home/apt.
Of the room types, entire home/apt accounted for 54.96% of listings.
Listings were available for 148.75 days a year on average, but this could range from no availability to being available all year round.
There were anywhere from none to many reviews for each listing, which suggested different levels of interaction or length of time listed on the platform.
The average number of reviews per month was 1.08, although this varies substantially between listings.

```{r summ}
# Check summary statistics of the data
print(dfSummary(data, text.graph.col = FALSE, graph.col = FALSE, style = "grid", valid.col = FALSE), headings = FALSE, max.tbl.height = 400, footnote = NA, col.width=5, method="render")
```

### 1.2 Missing values, drop columns

Managing missing values was one of the critical problems to fix before building the models.

The missing values for continuous variable `reviews_per_month` (10,352 rows) were imputed with 0 as it corresponded with 0 `number_of_reviews` (10,352 rows with 0 number of reviews).

The rest of the columns with missing values were not useful for the analysis and predictions: `host_name` and `name` columns contained name of the host and listing, column `last_review` contained information about the date of the last review.
The column `license` showed if a listing had license (according to the law, specific short-term rentals require a license), this column had more than 90% of the missing data and was dropped from the data.
Columns `id, host_id` were dropped as well.
Although, they didn't have any missing values, they contained unique identification numbers for each listing and host which were not useful for the further analysis.

```{r check_na}
dim(data[data$number_of_reviews == 0,])
```

```{r na_impute}
# Set seed for constant results
set.seed(42)

# Copy original data
imputed_df <- data

# Impute NAs for 'reviews_per_month' with their 0
imputed_df <- imputed_df %>% 
              mutate(across(c('reviews_per_month'), ~replace_na(., 0)))

imputed_df <- imputed_df %>% 
              dplyr::select(-c(id, host_id, host_name, name, last_review, license))
```

### 1.3 Encoding, rename colums

We assured that our dataset was appropriate for a broader range of algorithms that require numerical input by using one-hot encoding, boosting the potential accuracy and effectiveness of our later analysis.

`neighbourhood_group and room_type` were recognized as categorical columns that would benefit from one-hot encoding.

Three new columns were created for `room_type`: `Entire home/apt, Hotel room, and Private room`.
Each of these columns accepted a binary value, indicating whether the corresponding room type was present (1) or absent (0).

Three new columns were created for `neighbourhood_group`: `neighbourhood_group_Bronx, neighbourhood_group_Brooklyn, neighbourhood_group_Manhattan, neighbourhood_group_Queens`.
Each of these columns accepted a binary value, indicating whether the corresponding neighbourhood group was present (1) or absent (0).

The last category of each original categorical variable was eliminated throughout the encoding procedure to avoid multicollinearity and reduce redundancy (`neighbourhood_group_Staten Island, room_type_Shared room`).
The original columns were dropped after explanatory analysis.

The column names were fixed to remove space and transform all letters to lowercase using clean_names() function from janitor library.

Column `neighbourhood` wasn't encoded or used in the models as it was highly granular, with numerous distinct categories, and one-hot encoding could result in a dataset that was extremely high dimensional. We assumed it was not crucial for the prediction, given that we already had geographical coordinates and neighbourhood_group included.

```{r encode_binary}
# Copy data without NAs
encoded_df <- imputed_df

# One hot encoding for 'neighbourhood_group', 'neighbourhood', and 'room_type'  using library('fastDummies')
encoded_df <- dummy_cols(encoded_df, select_columns = c('neighbourhood_group','room_type'))

#encoded_df <- dummy_cols(encoded_df, select_columns = c('neighbourhood'))

encoded_df <- encoded_df %>%
           dplyr::select(-c('neighbourhood_group_Staten Island','room_type_Shared room')) %>% 
           clean_names()


#encoded_df <- encoded_df %>%
 #          dplyr::select(-c('neighbourhood_Fort Wadsworth')) %>% 
  #         clean_names()
```

### 1.4 Outliers

**FIX OUTLIERS**

```{r}
def turkey_outliars(df,column):
    Q1 = np.percentile(df[column],25)
    Q3 = np.percentile(df[column],75)
    IQR = Q3 - Q1
    outlier_step = 1.5 * IQR
    outliers_index = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step)].index
    return outliers_index
outliers_index = turkey_outliars(X_filled_clean,'price')

```

We used boxplots to detect outliers.

-   There were notable anomalies for the `price`, with certain listings charging astronomically high costs in contrast to the majority. Since it was New York City, such prices could have place in reality, we kept these outliers.

-   `minimum_nights` column also displayed anomalies, with certain listings having extraordinarily high minimum nights requirements. As we saw per graph, there were just 6 listings out of 38,792 with minimum number of nights greater than 500. Hosts could set up these high numbers of minimum nights when they didn't want to accept new guests. As a results, these number for minimum nights were not real. We removed them as these wrong numbers could skew the results. 


-   `number_of_reviews`, `reviews_per_month`. A small percentage of listings had an unusually high amount of total reviews. Some listings were more popular than others because they received a lot of reviews each month. For example, these listings could represent a hotel, each hotel could have a lot of rooms in one listing for rent. As a result, one listing received a lot of reviews for many rooms inside it. But the number of listings with reviews greater than 700 was just 9 and the number of reviews per month greater than 40 was 3, they were not representative of the typical listings, they were likely to skew your predictive modeling results. This is a common approach when the outliers constitute a very small percentage of the data and are not central to the analysis. Because the linear regression and Lasso regression models are sensitive to the size and distribution of the input features, outliers can significantly affect the performance of these models.

-   `calculated_host_listings_count`. Compared to the average host, some hosts had a lot more listings than others. Which could also happen in case some hosts owned multiple property.

-   `availability_365`. Listings with extremely high availability all year round could be properties that were specifically intended for rental use.

-   `number_of_reviews_ltm`: Some listings had received a significant amount of reviews in just the past year, comparable to the overall number of reviews. As it was mentioned above, it could be some hotels. The listings with number of reviews for the last 12 months greater than 200 were removed.

If these outliers were not properly addressed, they may represent special cases or mistakes in data entry, which could skew the analysis.

```{r outliers}
# Numeric columns to check for outliers
continuous_vars <- c("price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "availability_365", "number_of_reviews_ltm")

# List to store plots
plots <- list()

# Generate boxplots for each variable
for(i in 1:length(continuous_vars)) {
  p <- ggplot(encoded_df, aes_string(y = continuous_vars[i])) + 
    geom_boxplot() +
    theme_minimal()
  plots[[i]] <- p
}

# Arrange the plots in a grid
grid.arrange(grobs = plots, ncol = 3)
```

```{r}
dim(encoded_df[encoded_df$minimum_nights  > 500,])
dim(encoded_df[encoded_df$number_of_reviews  > 700,])
dim(encoded_df[encoded_df$reviews_per_month  > 40,])
dim(encoded_df[encoded_df$number_of_reviews_ltm  > 200,])

encoded_df <- encoded_df %>%
         filter(minimum_nights <= 500 & number_of_reviews  <= 700 & reviews_per_month  <= 40 & number_of_reviews_ltm  <= 200)
```



### 1.5 Column change

Columns `neighbourhood_group, neighbourhood, room_type` were transformed to categorical variables. This change was performed to better depict the variables' inherent categorical character.

```{r to_factor}
# Transform binary variables to factors
cols <- c("neighbourhood_group", "neighbourhood", "room_type")
encoded_df[cols] <- lapply(encoded_df[cols], factor) 
```



### 1.6 Summary Statistics for transformed data

After the data transformation, no missing values detected.

New columns were added (`neighbourhood_group_bronx, neighbourhood_group_brooklyn,  neighbourhood_group_manhattan, neighbourhood_group_queens, room_type_entire_home_apt,    room_type_hotel_room, room_type_private_room`) while other were removed (`id, name, host_id, host_name, last_review, license`).

Overall, where the outliers had been eliminated, the main changes brought about by filtering were seen in the maximum values of `minimum_nights, number_of_reviews, reviews_per_month, umber_of_reviews_ltm`. Because of this, the means and standard deviations of these variables had somewhat decreased, which had made the data more condensed and probably more appropriate for linear and Lasso regression analysis.

```{r head_data_new}
DT::datatable(
      encoded_df[1:25,],
      extensions = c('Scroller'),
      options = list(scrollY = 350,
                     scrollX = 500,
                     deferRender = TRUE,
                     scroller = TRUE,
                     dom = 'lBfrtip',
                     fixedColumns = TRUE, 
                     searching = FALSE), 
      rownames = FALSE) 
```

```{r summ_new}
print(dfSummary(encoded_df, text.graph.col = FALSE, graph.col = FALSE, style = "grid", valid.col = FALSE), headings = FALSE, max.tbl.height = 500, footnote = NA, col.width=50, method="render")
```



## 2. Data Exploration

### 2.1 Continuous Variables

`availability_365` displayed a distribution that was more variable. While some postings were available all year long, the most of the hosts were not available all the year. Latitude and longitude had a normal distribution, most of the hosts were concetrated in a specific area. All other distributions were right-skewed. Severe skewness in predictors or the target variable could be problematic in regression analysis because it could go against the normalcy assumption, particularly in linear regression models. In addition to causing non-linearity and heteroscedasticity (non-constant variance), skewed distributions can also make the model more susceptible to outliers. It was addressed after splitting the data for training and testing.

```{r cont_plot}
# Choose numeric variables
numeric_vars <-c("price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "availability_365", "number_of_reviews_ltm", "latitude", "longitude")

# List to store plots
plots <- list()

# Generate histograms for each variable
for (i in 1:length(numeric_vars)) {
  p <- ggplot(encoded_df, aes_string(x = numeric_vars[i])) + 
    geom_histogram(aes(y=..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    ggtitle(paste0('Distribution of ', numeric_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots,  ncol = 2)
```


### 2.2 Categorical Variables

The distribution of Airbnb listings among New York City's boroughs showed noticeably more listings in some boroughs than in others, which could indicate that there was more demand or a larger selection of lodging in those areas. The most properties were found in `Manhattan` followed by `Brooklyn` which was probably because it had been a popular destination for both leisure and business travelers.

The various kinds of rooms that were available in Airbnb listings showed that some room types were more common than others, which could be a reflection of the hosts' preferences or trends in visitor demand. `Entire home/apt` followed by `Private room` were the most common room type among all neighborhood groups, indicating that hosts in NYC were more likely to provide entire apartments as opposed to shared spaces.

It was crucial to comprehend these distributions in order to comprehend the dynamics of New York City's Airbnb listings. For instance, a borough with a lot of listings might be a commercial center or a well-liked vacation spot. In a similar vein, the popularity of a specific room type can reveal the kind of lodging that visitors to NYC usually look for.


```{r factor_plot}
# Choose factor variables
factor_vars <- c("neighbourhood_group", "room_type")

# List to store plots
plots <- list()

# Generate barplots for each variable
for (i in 1:length(factor_vars)) {
  p <- ggplot(encoded_df, aes_string(x = factor_vars[i])) + 
    geom_bar(fill = "lightgreen", color = "black", alpha = 0.7) +
    ggtitle(paste0('Distribution of ', factor_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots, ncol = 1)
```


Plotting the distribution of Airbnb properties by type of room across several neighborhood groups in New York City, the data was displayed as a grouped bar chart below. 

Manhattan was followed by Brooklyn in terms of the quantity of Airbnb listings. Entire home/apt was the most popular listing, followed by Private room. This suggests that Airbnb stays were also common in Brooklyn.

Compared to Manhattan and Brooklyn, there were noticeably fewer listings in Queens, the Bronx, and Staten Island. Of these, Queens had a higher number of listings than Staten Island and the Bronx.

In all boroughs, private room listings were the second most prevalent, with a notable concentration in Brooklyn and Manhattan.

There weren't many listings for shared rooms, which could be because hosts prefer not to provide shared spaces or because there weren't as much demand for this kind of lodging.

There were variations in the distribution of room types among the boroughs, which could be due to factors such as the local housing market, zoning laws, or the travel and demographic patterns of each community.



```{r borough_room}
# Group by borough, count room type in each borough
group_room <- encoded_df %>%
  group_by(neighbourhood_group) %>%
  count(room_type)

# Bar plot borough vs number of listings by room type
ggplot(group_room, aes(x = neighbourhood_group, y = n, fill = room_type)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme_minimal() +
  labs(title = "Borough vs Properties, NYC", x = "Borough", y = "Number of Properties") +
  scale_fill_discrete(name = "Room Type") 

```


The mix of neighborhoods in the top 10 reflected the diverse appeal of New York City's numerous neighborhoods by showcasing a range of areas dispersed across different parts of the city.

The neighborhood's strong representation of Williamsburg and Bedford-Stuyvesant underscored Brooklyn's growing appeal as a destination for travelers to New York City.

The list included Manhattan neighborhoods like Harlem, Hell's Kitchen, Upper West Side, and Upper East Side, highlighting the city's ongoing appeal because of its convenient location and wealth of attractions.

Popular neighborhoods that draw a varied range of visitors included those with cultural, historical, or entertainment significance, such as Hell's Kitchen and Harlem, which are well-known for their restaurants and close proximity to Broadway.


```{r neigh_count}
group_neigh <- encoded_df %>% 
  group_by(neighbourhood) %>% 
  count() %>% 
  arrange(desc(n))

ggplot(group_neigh[1:10,], aes(x = reorder(neighbourhood, -n), y = n, fill = neighbourhood)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme_minimal() +
  labs(title = "Neighbourhood vs Properties, NYC", x = "Neighbourhood", y = "Number of Properties") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")
```


### 2.3 Target variable

**Price vs Numerical Variables**: Price didn't seem to be strongly correlated with either latitude or longitude. Nonetheless, there were pockets of higher pricing in specific locations, most likely associated with upscale or more well-known neighborhoods. Few listings had a very high minimum night requirement, while the majority of listings had fewer minimum nights. The quantity of required minimum nights and the cost did not exhibit a definite linear relationship. The majority of expensive listings did not require a minimum of one night.

In general, listings with a large number of reviews were less expensive. This could suggest that listings at lower prices were being booked and reviewed more frequently. The prices of the listings with fewer reviews varied greatly. Listings with more reviews per month typically had lower prices, much like the number of reviews does. Additionally, this plot implied that listings that were reviewed and probably booked more frequently were more reasonably priced.

The price and the quantity of listings a host had were not clearly correlated. Prices varied widely for hosts with few or many listings. The prices for the various yearly availability levels varied greatly.
The lack of a discernible pattern suggested that price couldn't be strongly correlated with availability. Similar to the total number of reviews, listings with a higher number of recent reviews typically had lower prices. The trend suggested that listings with lower prices could be booked and reviewed more frequently.

```{r numeric_price}
# Plot target vs numeric columns
for (i in numeric_vars) {
  p <- ggplot(encoded_df, aes_string(x = i, y = "price")) +
    geom_point() +
    theme_bw() +
    labs(title = paste('Price vs', i), x = i, y = 'Price')
  
  print(p)
}
```

**Price vs Categorical Variables**: 

The median prices of various neighborhood groups differed noticeably from one another. The common belief that Manhattan was a more expensive area was supported by the fact that the borough's median prices tend to be higher than those of other Manhattan neighborhoods. Compared to individual rooms and hotel rooms, entire homes and apartments were typically more expensive. There was a significant variance in the kind and caliber of these listings, as seen by the larger price variance for complete houses or apartments.

```{r}
# Plot target vs categorical
for (i in factor_vars) {
  p <- ggplot(encoded_df, aes_string(x = i, y = "price")) +
    geom_boxplot() +
    theme_bw() +
    labs(title = paste('Price vs', i), x = i, y = 'Price')
  print(p)
}
```


It appeared that a listing's location (shown by latitude and longitude) affected its price, but not in a straightforward linear way. It was likely that neighborhood-specific factors were important. A few factors that clearly affected price were the type of room and the quantity of reviews. Listings with lower prices appeared to draw more reviews. A large number of the numerical variables didn't clearly demonstrate a linear relationship with price, suggesting that the intricacies of the data could be beyond the scope of a basic linear model.
Possibility of Non-linear and Interaction Effects: Non-linear modeling or the addition of interaction terms could be required to more accurately depict the relationship between these variables and the price, given the absence of obvious linear trends.

### 2.4 Correlation

There was a positive correlation between higher `prices` and listings in `Manhattan` (0.15). This implied that Manhattan real estate was more expensive to list, probably as a result of the borough's popularity and strategic location. In contrast, there was a negative correlation (-0.09 and -0.07, respectively) between the price of listings in Brooklyn and Queens, suggesting that these boroughs typically had lower prices than Manhattan. 

`Price` and `entire homes/apartments` had a positive correlation (0.10), indicating that the price of these listings was usually higher than that of shared accommodations. A negative correlation (-0.11) indicated that private rooms were typically less expensive than whole houses or apartments. 

Price and longitude had a negative correlation (-0.11), which could suggest that listings in Brooklyn and Queens, which are further east, were typically less expensive.
The positive correlation between latitude and price was less strong (0.03), indicating a potential trend toward slightly higher listing prices for listings further north.

The neighbourhood group encodings exhibited significant negative correlations with each other. For example, the correlation between neighbourhood group Manhattan and neighbourhood group Brooklyn was -0.56, and the correlation between neighbourhood group Manhattan and neighbourhood group Queens was -0.36. Given that these were mutually exclusive categories, this was expected.

Correlations between room type encodings and neighbourhood groups were also strongly negative. For example, there was a negative correlation (-0.81) between room_type_Private room and room_type_Entire home/apt. This suggested that these kinds of rooms belong to exclusive groups.

There was a significant inverse relationship between latitude and longitude (-0.48). This implied a geographical trend that was geographically accurate for New York City: moving west corresponds with moving north (higher latitude).

The relationship between availability_365 and calculated_host_listings_count was moderately positive (0.22). This could suggest that hosts who had a larger number of listings were typically more available all year long.

There existed a moderate negative correlation (-0.11) between number_of_reviews and calculated_host_listings_count. This could indicate that hosts with fewer properties tended to have listings that had received more reviews, either because they had been active on the platform longer or because they concentrated more on a single listing.


```{r corr}
# Check correlation
rcore <- rcorr(as.matrix(encoded_df %>% dplyr::select(where(is.numeric))))
# Take correlation coeff
coeff <- rcore$r
# Build corr plot
corrplot(coeff, tl.cex = 0.5, tl.col="black", method = 'color', addCoef.col = "black",
         type="upper", order="hclust", number.cex=0.5,
         diag=FALSE)
```

```{r corr_numbers}
tst <- encoded_df %>% dplyr::select(where(is.numeric))
tst <- tst[,-3]
kable(cor(drop_na(tst))[,3], "html", escape = F, col.names = c('Coefficient')) %>%
  kable_styling("striped", full_width = F) %>%
  column_spec(1, bold = T) 
```


## 3. Split data

Finally, we split our data into train (75%) and test (25%) datasets to evaluate model performance before we proceeded to prediction. The train data contained 29,201 records, test data 9,567.

```{r split}
# random seed
set.seed(42)

# 80/20 split of the data set
sample <- sample.split(encoded_df$price, SplitRatio = 0.75)
train_data  <- subset(encoded_df, sample == TRUE)
test_data   <- subset(encoded_df, sample == FALSE)

# Check dimensions of train and test data
dim(train_data)
dim(test_data)
```

As outliers showed, the were extremely high prices per night (`$30,000`) in contrast to the mean (`$216`). As a result, the price distribution was right-skewed. This indicated that the skewness was positive. To lessen the skewness, log transformation was used after splitting the data for training and testing to avoid data leakage. Transformation by log+1 was preferable because division by zero was problematic. We also applied the Box-Cox Transformation to `minimum_nights, number_of_reviews, reviews_per_month, calculated_host_listings_count, number_of_reviews_ltm` due to their right-skeweness to stabilize variance and improve its normalcy. We added 1 in boxCox() to ensure all values were positive, which is necessary for the Box-Cox transformation

```{r transform, fig.keep="none"}
# Log transformation for target variable to remove skeweness
train_transformed <- train_data
test_transformed <- test_data

# Log transformation for "price","minimum_nights"
cols_transform <- c("price","minimum_nights")

for (i in cols_transform) {
  train_transformed[[i]]<- log(train_transformed[[i]]+1)
  test_transformed[[i]]<- log(test_transformed[[i]]+1)
}

# Boxcox transformation for "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "number_of_reviews_ltm"
b_boxcox <- boxcox(lm((train_transformed$number_of_reviews+1) ~ 1))
b_lambda <- b_boxcox$x[which.max(b_boxcox$y)]
b_trans <- BoxCox(train_transformed$number_of_reviews+1, b_lambda)
train_transformed$number_of_reviews <- b_trans 
b_trans <- BoxCox(test_transformed$number_of_reviews+1, b_lambda)
test_transformed$number_of_reviews <- b_trans 


c_boxcox <- boxcox(lm((train_transformed$reviews_per_month+1) ~ 1))
c_lambda <- c_boxcox$x[which.max(c_boxcox$y)]
c_trans <- BoxCox(train_transformed$reviews_per_month+1, c_lambda)
train_transformed$reviews_per_month <- c_trans 
c_trans <- BoxCox(test_transformed$reviews_per_month+1, c_lambda)
test_transformed$reviews_per_month <- c_trans 

d_boxcox <- boxcox(lm((train_transformed$calculated_host_listings_count) ~ 1))
d_lambda <- d_boxcox$x[which.max(d_boxcox$y)]
d_trans <- BoxCox(train_transformed$calculated_host_listings_count, d_lambda)
train_transformed$calculated_host_listings_count <- d_trans 
d_trans <- BoxCox(test_transformed$calculated_host_listings_count, d_lambda)
test_transformed$calculated_host_listings_count <- d_trans 

e_boxcox <- boxcox(lm((train_transformed$number_of_reviews_ltm+1) ~ 1))
e_lambda <- e_boxcox$x[which.max(e_boxcox$y)]
e_trans <- BoxCox(train_transformed$number_of_reviews_ltm+1, e_lambda)
train_transformed$number_of_reviews_ltm <- e_trans 
e_trans <- BoxCox(test_transformed$number_of_reviews_ltm+1, e_lambda)
test_transformed$number_of_reviews_ltm <- e_trans 
```

For linear regression models, these transformations aided in stabilizing the variance and improving the symmetry of the distributions. The data was better suited for predictive modeling after transformations.

```{r cont_plot}
# Choose numeric variables
numeric_vars <-c("price", "minimum_nights", "number_of_reviews", "reviews_per_month", "calculated_host_listings_count", "availability_365", "number_of_reviews_ltm")

# List to store plots
plots <- list()

# Generate histograms for each variable
for (i in 1:length(numeric_vars)) {
  p <- ggplot(train_transformed, aes_string(x = numeric_vars[i])) + 
    geom_histogram(aes(y=..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
    geom_density(alpha = 0.2, fill = "#FF6666") +
    ggtitle(paste0('Distribution of ', numeric_vars[i])) +
    theme_minimal()
  plots[[i]] <- p
}

# Plot in grid with 3 columns
grid.arrange(grobs = plots, ncol = 2)
```



## 4. Models

### 4.1 Model 1- 
Adjusted R-squared:  0.4464 F-statistic:  1570 on 15
```{r}
set.seed(42)
ctrl <- trainControl(method = "cv", number = 5)

#fit a regression model and use k-fold CV to evaluate performance
model_2 <- train(price ~ ., data = train_model_1, method = "lm", trControl = ctrl)
print(model)
summary(model_2)
```


```{r, fig.height=4}
# validate and calculate RMSE
model_2.valid <- predict(model_2, newdata = test_model_1)
model_2.eval <- bind_cols(target = test_model_1$price, predicted=unname(model_2.valid))
model_2.rmse <- sqrt(mean((model_2.eval$target - model_2.eval$predicted)^2)) 

# plot targets vs predicted
model_2.eval %>%
  ggplot(aes(x = target, y = predicted)) +
  geom_point(alpha = .3) +
  geom_smooth(method="lm", color='grey', alpha=.3, se=FALSE) +
  labs(title=paste('RMSE:',round(model_1_aic.rmse,1)))
```

```{r}
model2_df <- model_2.eval %>% multi_metric(truth=target, estimate=predicted)
b <- summary(model_2)
```

```{r}
results_lm_tbl <- tibble(
                      Model = character(),
                      mape = numeric(), 
                      smape = numeric(), 
                      mase = numeric(), 
                      mpe = numeric(), 
                      "RMSE" = numeric(),
                      AIC = numeric(),
                      "Adjusted R2" = numeric(),
                      "F-statistic" = numeric()
                )

results_lm_tbl <- results_lm_tbl %>% add_row(tibble_row(
                      Model = "Model 1: Linear Regression, cv",
                      mape = model2_df[[1,3]],
                      smape = model2_df[[2,3]],
                      mase = model2_df[[3,3]],
                      mpe = model2_df[[4,3]],
                      "RMSE" = model2_df[[5,3]],
                      AIC = AIC(model_2$finalModel),
                      "Adjusted R2" = b$adj.r.squared,
                      "F-statistic" = b$fstatistic[1]
                     ))
```



```{r check_lm1}
check_model(model_1_aic, check=c('ncv','qq','homogeneity','outliers'))
```

```{r vif_lm1, fig.height=4}
vif_values <- vif(model_1_aic)
vif_values <- rownames_to_column(as.data.frame(vif_values), var = "var")

vif_values %>%
  ggplot(aes(y=vif_values, x=var)) +
  coord_flip() + 
  geom_hline(yintercept=5, linetype="dashed", color = "red") +
  geom_bar(stat = 'identity', width=0.3 ,position=position_dodge()) 
```

### 4.3 Model 3 - Lasso

To perform lasso regression, we’ll use functions from the glmnet package. This package requires the response variable to be a vector and the set of predictor variables to be of the class data.matrix.

```{r}
set.seed(42)
t0 <- train_data %>% dplyr::select(-c(neighbourhood_group,neighbourhood, room_type))
X <- model.matrix(price ~ ., data=t0)[,-1]
y <- t0$price
```

Next, we’ll use the glmnet() function to fit the lasso regression model and specify alpha=1.

To determine what value to use for lambda, we’ll perform k-fold cross-validation and identify the lambda value that produces the lowest test mean squared error (MSE).
```{r}
set.seed(42)
cv_model <- cv.glmnet(
  x=X,y=Y, # Y already logged in prep
  family = "gaussian",
  type.measure="mse",
  standardize = TRUE, # standardize
  nfold = 10,
  alpha=1) # alpha=1 is lasso

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda


#produce plot of test MSE by lambda value
plot(cv_model) 
```


Lastly, we can analyze the final model produced by the optimal lambda value.


```{r}
#find coefficients of best model
best_model <- glmnet(X, y, alpha = 1, lambda = best_lambda)
coef(best_model)
```



```{r}
t1 <- test_data %>% dplyr::select(-c(neighbourhood_group,neighbourhood, room_type))
X_test <- model.matrix(price ~ ., data=t1)[,-1]
y_test <- t1[,"price"] 
```

```{r}
y_pred <- predict(
  best_model, 
  newx = X_test,
  #type = "response",
  s = best_lambda)
```

```{r}
t2 <- t1
t2$price_pred <- y_pred[,1]

m_df <- t2 %>% multi_metric(truth=price, estimate=price_pred)
m_df
```

```{r}
results_lm_tbl <- results_lm_tbl %>% add_row(tibble_row(
                      Model = "Model 3: Lasso",
                      mape = m_df[[1,3]],
                      smape = m_df[[2,3]],
                      mase = m_df[[3,3]],
                      mpe = m_df[[4,3]],
                      "RMSE" = m_df[[5,3]],
                      AIC = NA,
                      "Adjusted R2" = NA,
                      "F-statistic" = NA
                     ))
```






Descriptive Statistics Overview:
Latitude & Longitude: These are geographic coordinates, which might be useful to understand the spatial distribution of prices.
Price: There's a significant range in prices, with a maximum of $30,000, which seems quite high. The mean is $215.89, but the median is much lower at $135, indicating a right-skewed distribution.
Minimum Nights: Majority of listings require a 30-night stay, but some listings require up to 500 nights, which is quite high.
Number of Reviews: Varies widely, indicating different levels of popularity or longevity of listings.
Reviews per Month: Some listings have high activity, while others have none.
Calculated Host Listings Count: Indicates how many listings each host manages, ranging from 1 to 602.
Availability_365: Ranges from 0 to 365 days, indicating varying levels of availability throughout the year.
Number of Reviews LTM (Last Twelve Months): Provides recent activity level of the listing.
Encoded Neighbourhood Groups & Room Types: These are categorical variables encoded as binary, useful for regression analysis.
Next steps in the analysis process:

Feature Selection:
We need to determine which features are most relevant to predicting the price. The encoded neighborhood groups and room types are definitely important. Other factors like location (latitude and longitude), availability, and host listing count may also play a significant role.

------------------------------------------------------------------------

Methodologies:

Week 4: Classification: Naive Bayes

Employ Naive Bayes classification to predict Airbnb listing categories (entire apartment, private room, shared room) based on listing characteristics.

Week 12: Resampling and Model Selection

Utilize k-fold cross-validation and train-test split techniques to evaluate the performance of various regression models (linear regression, ridge regression, Lasso regression) in predicting Airbnb listing prices.
Analysis:

Exploratory Data Analysis: Visualize and summarize the data to understand the distribution of variables and identify potential relationships between them.

Feature Engineering: Create new features from existing data to capture additional information and improve the predictive power of the models.

Model Building: Train and evaluate various regression models using the prepared data and the selected methodologies.

Model Validation: Assess the performance of the final model using unseen data to validate its generalizability.

Conclusions:

Identify the most significant factors influencing Airbnb listing prices in New York City.
Develop a predictive model that accurately estimates Airbnb listing prices based on the identified factors.
Provide insights into pricing strategies and market trends for Airbnb hosts in New York City.
Business Impact:

Help Airbnb hosts optimize their listing prices to maximize revenue and occupancy rates.
Assist potential Airbnb guests in making informed decisions based on price and listing characteristics.
Provide valuable insights to policymakers and urban planners for understanding the dynamics of the short-term rental market in New York City.
